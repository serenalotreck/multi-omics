{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import datatable as dt\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "from torch_geometric.datasets import QM7b\n",
    "os.chdir(\"/mnt/home/seguraab/Shiu_Lab/Collabs/Multi_Omic/multi-omics/GCN\")\n",
    "import simple_GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dataset - write unittest for this below\n",
    "--------------------------------------------\n",
    "MoleculeNet: A Benchmark for Molecular Machine Learning\n",
    "Zhenqin Wu et al. 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QM7b(7211)\n",
      "tensor([[ 0,  0,  0,  ..., 14, 14, 14],\n",
      "        [ 0,  1,  2,  ..., 12, 13, 14]])\n",
      "[[ 0  0  0 ... 14 14 14]\n",
      " [ 0  1  2 ... 12 13 14]]\n",
      "[(0, 0), (0, 1), (0, 2), (0, 3), (0, 4)]\n",
      "tensor([[-4.2093e+02,  3.9695e+01,  6.2184e-01,  ...,  1.0870e+00,\n",
      "          2.5346e+00,  2.4322e+00],\n",
      "        [-7.1842e+02,  2.2622e+01,  6.2833e-01,  ...,  1.1186e+00,\n",
      "          4.3320e+00,  4.4450e+00],\n",
      "        [-5.7002e+02,  2.2941e+01,  7.0906e-01,  ...,  1.9456e+00,\n",
      "          4.1733e+00,  3.9231e+00],\n",
      "        ...,\n",
      "        [-1.3301e+03,  1.0801e+01,  8.7788e-01,  ...,  7.0850e-01,\n",
      "          1.2768e+01,  1.3187e+01],\n",
      "        [-1.3555e+03,  1.0697e+01,  6.0990e-01,  ...,  6.4030e-01,\n",
      "          1.3711e+01,  1.3445e+01],\n",
      "        [-1.4944e+03,  1.0724e+01,  7.5581e-01,  ...,  6.0450e-01,\n",
      "          1.3670e+01,  1.4056e+01]])\n"
     ]
    }
   ],
   "source": [
    "dataset = QM7b(root=\"/tmp/Cora\")\n",
    "edge_index = dataset.data.edge_index\n",
    "edges_raw = dataset.data.edge_index.numpy()\n",
    "edges = [(x, y) for x, y in zip(edges_raw[0, :], edges_raw[1, :])]\n",
    "labels = dataset.data.y#.numpy()\n",
    "print(dataset)\n",
    "print(edge_index)\n",
    "print(edges_raw)\n",
    "print(edges[:5])\n",
    "print(labels) # regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 25], edge_attr=[25], y=[1, 14], num_nodes=5)\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genotype data analysis below this\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/48152674/how-to-check-if-pytorch-is-using-the-gpu\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.device(0)\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)\n",
    "print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB') # Memory\n",
    "print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB') # Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ufs18/home-056/seguraab/Shiu_Lab/Collabs/Multi_Omic'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate memory of size 3627113011[errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_84321/3261647477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpheno_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Phenotype_value_383_common_accessions_2017_Grimm.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgeno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeno_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# read in genotype data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mgeno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert dataframe to pandas dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgeno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# set index to sample ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate memory of size 3627113011[errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "#/mnt/home/seguraab/Shiu_Lab/Collabs/Multi_Omic/SNP_binary_matrix_383_accessions_drop_all_zero_MAF_larger_than_0.05_converted.csv\n",
    "#/mnt/home/seguraab/Shiu_Lab/Collabs/Multi_Omic/Phenotype_value_383_common_accessions_2017_Grimm.csv\n",
    "geno_data=\"SNP_binary_matrix_383_accessions_drop_all_zero_MAF_larger_than_0.05_converted.csv\"\n",
    "pheno_data=\"Phenotype_value_383_common_accessions_2017_Grimm.csv\"\n",
    "\n",
    "geno = dt.fread(geno_data) # read in genotype data\n",
    "geno = geno.to_pandas() # convert dataframe to pandas dataframe\n",
    "geno = geno.set_index(geno.columns[0], drop=True) # set index to sample ID\n",
    "geno = geno.sort_values(by=geno.columns[0], axis=0) # sort values by sample ID\n",
    "geno_sub = geno.iloc[:,0:1000]\n",
    "features = geno_sub.columns # columns as features\n",
    "\n",
    "pheno = pd.read_csv(pheno_data, index_col=0) # read in phenotype data\n",
    "label = pheno.FT10_mean # flowering time as label\n",
    "\n",
    "# Split geno and pheno into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(geno_sub, label, test_size=64)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train.values.astype(np.float32))#, device = \"cuda:1\") #0\n",
    "X_test = torch.tensor(X_test.values.astype(np.float32))#, device = \"cuda:1\")\n",
    "y_train = torch.tensor(y_train.values.astype(np.float32))#, device = \"cuda:1\") #0 2 \n",
    "y_test = torch.tensor(y_test.values.astype(np.float32))#, device = \"cuda:1\") #3\n",
    "    \n",
    "#X_train = X_train.to(device=\"cpu\")\n",
    "#X_test = X_test.to(device=\"cpu\")\n",
    "#y_train = y_train.to(device=\"cpu\")\n",
    "#y_test = y_test.to(device=\"cpu\")\n",
    "\n",
    "#train_tensor = data.TensorDataset(X_train, y_train) # Tensor training dataset to feed\n",
    "#train_loader = data.DataLoader(dataset = train_tensor, batch_size = 10, shuffle = True, pin_memory = False) # data loader to feed training data to network\n",
    "#test_tensor = data.TensorDataset(X_test, y_test)\n",
    "#test_loader = data.DataLoader(dataset=test_tensor, shuffle = True, pin_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial attempt to compute adjacency matrix\n",
    "from scipy import spatial\n",
    "# Given that cos_sim(u, v) = dot(u, v) / (norm(u) * norm(v))\n",
    "#                          = dot(u / norm(u), v / norm(v))\n",
    "# We fist normalize the rows, before computing their dot products via transposition:\n",
    "X_train_norm = F.normalize(X_train)\n",
    "res = torch.mm(X_train_norm, X_train_norm.transpose(0,1)) # idk if this is right\n",
    "print(res)\n",
    "\n",
    "### Source:\n",
    "# https://stackoverflow.com/questions/50411191/how-to-compute-the-cosine-similarity-in-pytorch-for-all-rows-in-a-matrix-with-re\n",
    "# https://github.com/pytorch/pytorch/issues/11202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "t_geno_sub = geno_sub.transpose()\n",
    "adj = cosine_similarity(t_geno_sub)\n",
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs\n",
    "'''\n",
    "MOGONET Method for Computing Adjacency Matrix\n",
    "1. Calculate adjacency matrix parameter (cal_adj_mat_parameter)\n",
    "    a. Compute cosine similarity matrix (cosine_distance_torch)\n",
    "2. Generate adjacency matrix tensor (gen_adj_mat_tensor)\n",
    "    a. Compute cosine similarity matrix (cosine_distance_torch)\n",
    "    b. Generate graph from distance matrix (graph_from_dist_torch)\n",
    "    c. Compute adj 1-dist ?? what's this\n",
    "    d. Multiply graph by adj\n",
    "    e. Transpose adj\n",
    "    f. Compute identity matrix\n",
    "    g. Compute adjacency matrix (not equation 2 in paper)\n",
    "3. Generate test adjacency matrix tensor (gen_test_adj_mat_tensor)\n",
    "'''\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "def cosine_distance_torch(x1, x2=None, eps=1e-8):\n",
    "    x2 = x1 if x2 is None else x2\n",
    "    w1 = x1.norm(p=2, dim=1, keepdim=True)\n",
    "    w2 = w1 if x2 is x1 else x2.norm(p=2, dim=1, keepdim=True)\n",
    "    return 1 - torch.mm(x1, x2.t()) / (w1 * w2.t()).clamp(min=eps)\n",
    "\n",
    "dist = cosine_distance_torch(X_train)\n",
    "print(dist)\n",
    "\n",
    "def cal_adj_mat_parameter(edge_per_node, data, metric=\"cosine\"):\n",
    "    assert metric == \"cosine\", \"Only cosine distance implemented\"\n",
    "    dist = cosine_distance_torch(data, data)\n",
    "    parameter = torch.sort(dist.reshape(-1,)).values[edge_per_node*data.shape[0]]\n",
    "    return np.asscalar(parameter.data.cpu().numpy())\n",
    "\n",
    "def graph_from_dist_tensor(dist, parameter, self_dist=True):\n",
    "    if self_dist:\n",
    "        assert dist.shape[0]==dist.shape[1], \"Input is not pairwise dist matrix\"\n",
    "    g = (dist <= parameter).float() # binary 0s and 1s for False/True\n",
    "    if self_dist:\n",
    "        diag_idx = np.diag_indices(g.shape[0])\n",
    "        g[diag_idx[0], diag_idx[1]] = 0\n",
    "    return g\n",
    "\n",
    "def to_sparse(x):\n",
    "    x_typename = torch.typename(x).split('.')[-1]\n",
    "    sparse_tensortype = getattr(torch.sparse, x_typename)\n",
    "    indices = torch.nonzero(x)\n",
    "    if len(indices.shape) == 0:  # if all elements are zeros\n",
    "        return sparse_tensortype(*x.shape)\n",
    "    indices = indices.t()\n",
    "    values = x[tuple(indices[i] for i in range(indices.shape[0]))]\n",
    "    return sparse_tensortype(indices, values, x.size())\n",
    "\n",
    "def gen_adj_mat_tensor(data, parameter, metric=\"cosine\"):\n",
    "    assert metric == \"cosine\", \"Only cosine distance implemented\"\n",
    "    dist = cosine_distance_torch(data, data)\n",
    "    g = graph_from_dist_tensor(dist, parameter, self_dist=True)\n",
    "    if metric == \"cosine\":\n",
    "        adj = 1-dist\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    adj = adj*g \n",
    "    adj_T = adj.transpose(0,1)\n",
    "    I = torch.eye(adj.shape[0])\n",
    "    if cuda:\n",
    "        I = I.cuda('cuda:0')\n",
    "    adj = adj + adj_T*(adj_T > adj).float() - adj*(adj_T > adj).float()\n",
    "    adj = F.normalize(adj + I, p=1)\n",
    "    adj = to_sparse(adj)   \n",
    "    return adj\n",
    "\n",
    "adj_parameter = 2 # edge_per_node\n",
    "adj_parameter_adaptive = cal_adj_mat_parameter(adj_parameter, X_train, \"cosine\")\n",
    "print(adj_parameter_adaptive) # this must be the threshold Ïµ the paper talks about\n",
    "adj_train = gen_adj_mat_tensor(X_train, adj_parameter_adaptive, \"cosine\")\n",
    "adj_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs\n",
    "cos = nn.CosineSimilarity()\n",
    "output = cos(X_train.t(), X_train.t())\n",
    "output\n",
    "\n",
    "# vs\n",
    "output2 = F.cosine_similarity(X_train.t(), X_train.t())\n",
    "output2 # same as output\n",
    "\n",
    "# vs\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "adj_mat = cosine_similarity(X_train.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network\n",
    "net = simple_GCN.GCN(in_channels = X_train.size()[1], out_channels = [X_train.size()[1], 500, X_train.size()[0]]).to(device=\"cuda:4\")\n",
    "net = net.to(device=\"cuda:4\")\n",
    "print(net)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.2) # optimizer (variant of gradient descent)\n",
    "loss_func = torch.nn.MSELoss()  # mean squared loss function for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34906/3957621346.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Memory Usage:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Allocated:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cached:   '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# Train the network\n",
    "print(\"Training... \")\n",
    "for epoch in range(500):\n",
    "    current_loss = 0.0\n",
    "    print(f\"\\nTest: Epoch {epoch}\")\n",
    "    for input, batch in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()           # clear gradients for next train\n",
    "            inputs, target = batch\n",
    "            print(\"inputs\", inputs)\n",
    "            print(\"target\", target)\n",
    "            prediction = net(inputs) #, output2)             # prediction based on input x\n",
    "            loss = loss_func(prediction, target) # must be (1. nn output, 2. target)\n",
    "            loss.backward()                 # backpropagation, compute gradients\n",
    "            optimizer.step()                # apply gradients\n",
    "\n",
    "            # print statistics\n",
    "            current_loss += loss.item()\n",
    "            print('Loss after mini-batch %5d: %.3f' % (input + 1, current_loss / 500))\n",
    "            current_loss = 0.0\n",
    "    \n",
    "end = time.time()   \n",
    "elapsed = end - start\n",
    "print(\"Training complete; Elapsed time: \", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate trained model on test set\n",
    "net.eval()\n",
    "_, pred = net(test_tensor).max(dim=1) \n",
    "correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / int(data.test_mask.sum())\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1facc6c99338aabf17cc297ef46753d1d5e292101e17ca23b8c6f09b87e93ba4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('torch-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
